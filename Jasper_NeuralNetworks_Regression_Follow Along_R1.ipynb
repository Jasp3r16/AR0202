{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f374ab",
   "metadata": {},
   "source": [
    "# Neural Networks for Non-Linear Regression\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "#### Import the Dataset\n",
    "#### Review the Data\n",
    "#### Train the Model\n",
    "#### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af113c1",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953e4e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#update the folder variable. Enter it as a string and make sure to use forward slashes (/) or double back slashes (\\\\)\n",
    "folder = 'filelocation'\n",
    "data_file_location = folder + '\\\\concrete_data.csv'\n",
    "save_file_location = folder + '\\\\concrete_data_with_predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5244e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the CSV File\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_location, sep=\";\", header=0)\n",
    "\n",
    "#Print the dataframe to check it\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d324f3f-4490-4877-a917-7e6226817913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(['compressive_strength'], axis=1)\n",
    "y = df.compressive_strength\n",
    "\n",
    "#assign the df to a new variable\n",
    "X_norm = X\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "#normalize the values and save them to the new dataframe\n",
    "for index, row in X_norm.iterrows():\n",
    "    X_norm.at[index, 'cement'] = X_normalized[index, 0]\n",
    "    X_norm.at[index, 'slag'] = X_normalized[index, 1]\n",
    "    X_norm.at[index, 'fly_ash'] = X_normalized[index, 2]\n",
    "    X_norm.at[index, 'water'] = X_normalized[index, 3]\n",
    "    X_norm.at[index, 'superplasticizer'] = X_normalized[index, 4]\n",
    "    X_norm.at[index, 'coarse_aggregate'] = X_normalized[index, 5]\n",
    "    X_norm.at[index, 'fine_aggregate'] = X_normalized[index, 6]\n",
    "    X_norm.at[index, 'age'] = X_normalized[index, 7]\n",
    "\n",
    "\n",
    "print(tabulate(X_norm, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a2133-6147-482b-aa7e-0874c18f1dee",
   "metadata": {},
   "source": [
    "## Review the Data\n",
    "\n",
    "It's always a good idea to plot the features and target of your data set to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee611c8-6da2-4fb0-9867-2a22a70ed349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot features against target (strength)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot select features against the strength\n",
    "plt.scatter(X['cement'], y, s=25, c='r', label = \"cement\")\n",
    "plt.scatter(X['age'], y, s=25, c='m', label = \"age\")\n",
    "plt.title('Feature and Strength Visualization')\n",
    "plt.xlabel('Feature Value') \n",
    "plt.ylabel('Strength')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a3889-e048-4956-ae3d-0aa35e01363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot 2 features against the target (strength) with strength represented in the Z axis\n",
    "#use the Z filter to visualize points with strengths above a threshold\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#set Z filter value here\n",
    "z_filter = 60\n",
    "\n",
    "#3D plot to compare 2 features against the target\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "# Filter points where z < z_filter value\n",
    "mask_over_filter = y >= z_filter\n",
    "mask_under_filter = y < z_filter\n",
    "\n",
    "# Create a scatter plot with filtered points\n",
    "ax.scatter(X['cement'][mask_over_filter], X['age'][mask_over_filter], y[mask_over_filter], marker='^', color='blue')\n",
    "ax.scatter(X['cement'][mask_under_filter], X['age'][mask_under_filter], y[mask_under_filter], marker='^', color='orange', alpha = 0.2)\n",
    "\n",
    "ax.set_xlabel('cement')\n",
    "ax.set_ylabel('age')\n",
    "ax.set_zlabel('strength')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(X['cement'][mask_over_filter], X['age'][mask_over_filter], y[mask_over_filter], marker='^', color='blue')\n",
    "ax2.scatter(X['cement'][mask_under_filter], X['age'][mask_under_filter], y[mask_under_filter], marker='^', color='orange', alpha = 0.2)\n",
    "\n",
    "# Set labels for the top view plot\n",
    "ax2.set_xlabel('cement')\n",
    "ax2.set_ylabel('age')\n",
    "ax2.set_title('Top-Down View')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdadf6",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1878e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3,random_state=42) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77314f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a regression model using the MLPRegressor function\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50, 50, 50), activation='relu', solver='adam', max_iter=300)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882c29e-ccb0-4c64-98e8-9f769c6d4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(mlp.loss_curve_)\n",
    "ax.set_xlabel('Number of iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c58983",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d531452a-b718-4765-b377-3a13a097b7fb",
   "metadata": {},
   "source": [
    "Check the documentation to see what the .score() function returns\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54c461-4302-4531-93bc-f88ed377dd8b",
   "metadata": {},
   "source": [
    "Look at other metrics like Root Mean Squared Error and Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9128cd-63d5-448d-ab3c-2e72a76a1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904eb52-e079-4f80-99ad-860e339689f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c069fc-5001-486f-a8ec-bcc44ae365af",
   "metadata": {},
   "source": [
    "These metrics are relative to the scale of your output data. In our dataset, we measure the strength in MPa. It can be helpful to compare the errors against values in your dataset to understand the scale of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81453b11-00da-4dc5-b229-a1df75458622",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_value = df['compressive_strength'].min()\n",
    "highest_value = df['compressive_strength'].max()\n",
    "median_value = df['compressive_strength'].median()\n",
    "mean_value = df['compressive_strength'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Lowest value: {lowest_value}\")\n",
    "print(f\"Highest value: {highest_value}\")\n",
    "print(f\"Median value: {median_value}\")\n",
    "print(f\"Mean value: {mean_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec30b1-cc45-4965-9762-4e8ea799ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_median = round(rmse / median_value*100, 2)\n",
    "percentage_min = round(rmse / lowest_value*100, 2)\n",
    "percentage_max = round(rmse / highest_value*100, 2)\n",
    "\n",
    "print(\"RMSE is {}% of the median value of the dataset\".format(percentage_median))\n",
    "print(\"RMSE is {}% of the minimum value of the dataset\".format(percentage_min))\n",
    "print(\"RMSE is {}% of the maximum value of the dataset\".format(percentage_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7ce05-cd44-484b-90f3-c71f0e722329",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_median = round(mae / median_value*100, 2)\n",
    "percentage_min = round(mae / lowest_value*100, 2)\n",
    "percentage_max = round(mae / highest_value*100, 2)\n",
    "\n",
    "print(\"RMSE is {}% of the median value of the dataset\".format(percentage_median))\n",
    "print(\"RMSE is {}% of the minimum value of the dataset\".format(percentage_min))\n",
    "print(\"RMSE is {}% of the maximum value of the dataset\".format(percentage_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951ecb3-6356-4a7e-bbd7-1a0aa8088f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
